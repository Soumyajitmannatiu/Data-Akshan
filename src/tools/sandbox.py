from docker import errors
import docker
import os
import io
import tarfile
import time
import uuid

# --- Configuration ---
# NOW USING OUR CUSTOM BUILT IMAGE
DOCKER_IMAGE = "data-analyzer-sandbox:latest"
CODE_EXEC_TIMEOUT_SECONDS = 60
HOST_DATA_DIR = "./data"       # Directory on host where datasets are stored
HOST_OUTPUT_DIR = "./output"   # Directory on host where plots/cleaned data will be saved
CONTAINER_WORKSPACE = "/workspace" # Inside the container

# Ensure host directories exist
os.makedirs(HOST_DATA_DIR, exist_ok=True)
os.makedirs(HOST_OUTPUT_DIR, exist_ok=True)

# Initialize Docker client
client = docker.from_env()
def _normalize_container_path(path: str) -> str:
    """Ensures paths for Docker operations use forward slashes."""
    return path.replace('\\', '/')

def execute_sandboxed_code(code_string: str, input_files: list | None, output_files_expected: list | None):
    """
    Executes Python code in an isolated Docker container.

    Args:
        code_string (str): The Python code to execute.
        input_files (list): List of filenames (relative to HOST_DATA_DIR) to copy into the container.
                            E.g., ['my_data.csv', 'config.json']
        output_files_expected (list): List of filenames (relative to CONTAINER_WORKSPACE) expected
                                      to be generated by the code and copied back to HOST_OUTPUT_DIR.
                                      E.g., ['plot.png', 'cleaned_data.csv']

    Returns:
        dict: A dictionary containing stdout, stderr, execution_time, and a list of paths
              to any output files successfully retrieved.
    """
    if input_files is None:
        input_files = []
    if output_files_expected is None:
        output_files_expected = []

    container_id = f"adk-sandbox-{uuid.uuid4().hex}"
    host_output_temp_dir = os.path.join(HOST_OUTPUT_DIR, container_id) # Unique temp dir for this run
    os.makedirs(host_output_temp_dir, exist_ok=True)

    container = None # Initialize container to None for finally block
    stdout = ""
    stderr = ""
    execution_time = 0.0
    status_code = 1 # Default to error
    retrieved_output_paths = [] # Initialized here to be in scope for finally

    try:
        # 1. Prepare the full script to be run inside the container
        script_filename = "script.py"
        full_code = f"""
import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Ensure outputs go to specific location if needed, otherwise relative to CWD
# For robust plotting, ensure backend is non-interactive
plt.switch_backend('Agg')

{code_string}
"""
        # Create a tar archive in memory for the script
        script_tar_stream = io.BytesIO()
        with tarfile.open(fileobj=script_tar_stream, mode='w') as tar:
            script_data = full_code.encode('utf-8')
            tarinfo = tarfile.TarInfo(name=script_filename)
            tarinfo.size = len(script_data)
            tarinfo.mode = 0o755 # Make it executable
            tar.addfile(tarinfo, io.BytesIO(script_data))
        script_tar_stream.seek(0)

        # 2. Create and start a new container
        container = client.containers.run(
            DOCKER_IMAGE,
            detach=True,
            tty=True, # Allocate a pseudo-TTY so that we can attach later
            name=container_id,
            working_dir=_normalize_container_path(CONTAINER_WORKSPACE),
            # No command yet, we'll exec it after copying files
        )
        print(f"Started container: {container.id}")

        # Wait a moment for container to initialize
        time.sleep(0.5)

        # Copy the script file into the container
        container.put_archive(_normalize_container_path(CONTAINER_WORKSPACE), script_tar_stream.read())
        print(f"Copied {script_filename} to container.")

        # 3. Copy input files into the container
        for filename in input_files:
            host_path = os.path.join(HOST_DATA_DIR, filename)
            if not os.path.exists(host_path):
                print(f"Warning: Input file {host_path} not found on host.")
                continue
            
            with io.BytesIO() as tar_stream:
                with tarfile.open(fileobj=tar_stream, mode='w') as tar:
                    tar.add(host_path, arcname=filename)
                tar_stream.seek(0)
                container.put_archive(_normalize_container_path(CONTAINER_WORKSPACE), tar_stream.read())
            print(f"Copied {filename} to container.")

        # 4. Execute the script within the container
        exec_result = container.exec_run(
            cmd=_normalize_container_path(f"python {CONTAINER_WORKSPACE}/{script_filename}"), # <-- Apply normalization here
            stream=False,
            demux=True,
            user="root",
            environment={"PYTHONUNBUFFERED": "1"},
            # timeout=CODE_EXEC_TIMEOUT_SECONDS
        )
        start_time = time.time()
        status_code = exec_result.exit_code
        stdout = exec_result.output[0].decode('utf-8') if exec_result.output[0] else ""
        stderr = exec_result.output[1].decode('utf-8') if exec_result.output[1] else ""
        execution_time = time.time() - start_time
        
        print(f"Container script exited with status: {status_code}")
        if stdout: print(f"STDOUT:\n{stdout}")
        if stderr: print(f"STDERR:\n{stderr}")

        # Retrieve output files from the container
        for filename in output_files_expected:
            container_file_path = _normalize_container_path(os.path.join(CONTAINER_WORKSPACE, filename))
            host_save_path = os.path.join(host_output_temp_dir, filename)
            try:
                # Get the TAR stream
                strm, stat = container.get_archive(container_file_path)
                
                # Read stream into an in-memory buffer
                file_obj = io.BytesIO()
                for chunk in strm:
                    file_obj.write(chunk)
                file_obj.seek(0)

                # Open buffer as a TAR file and extract the actual file content
                with tarfile.open(fileobj=file_obj, mode='r') as tar:
                    # When requesting a single file, it's usually the first/only member
                    members = tar.getmembers()
                    if members:
                        extracted_f = tar.extractfile(members[0])
                        if extracted_f:
                            with open(host_save_path, 'wb') as f_out:
                                f_out.write(extracted_f.read())
                            retrieved_output_paths.append(host_save_path)
                            print(f"Retrieved and extracted: {filename} to {host_save_path}")
                        else:
                             print(f"Error: Could not extract data for {filename} from tar archive.")
                    else:
                         print(f"Error: Tar archive retrieved for {filename} was empty.")

            except errors.APIError as e:
                # Check for 404 Not Found specifically
                if e.status_code == 404:
                     print(f"Warning: File {filename} was not created by the script inside the container.")
                else:
                     print(f"Warning: Docker API error retrieving {filename}: {e}")
            except Exception as e:
                print(f"Error retrieving/extracting {filename}: {e}")
                pass

        return {
            "stdout": stdout,
            "stderr": stderr,
            "execution_time_seconds": execution_time,
            "retrieved_output_files": retrieved_output_paths,
            "status_code": status_code
        }

    except errors.ImageNotFound:
        stderr = f"Docker image '{DOCKER_IMAGE}' not found. Please build it with `docker build -t {DOCKER_IMAGE.split(':')[0]}:latest -f Dockerfile.sandbox .`."
        status_code = 1
    except errors.NotFound: # Raised if container_id does not exist when trying client.containers.get
        stderr = f"Docker container '{container_id}' not found during operation. It might have been removed prematurely or never created."
        status_code = 1
    except errors.APIError as e:
        stderr = f"Docker API error during sandbox execution: {e}"
        status_code = 1
    except Exception as e:
        stderr = f"An unexpected Python error occurred outside the container: {e}"
        status_code = 1
    finally:
        # Clean up: stop and remove the container
        if container: # Only attempt to clean up if container was successfully started
            try:
                # Ensure the container is stopped before removal.
                # If it's already stopped, this won't raise an error.
                container.stop(timeout=5)
                container.remove()
                print(f"Cleaned up container: {container_id}")

                # Clean up the temporary host_output_temp_dir if it's empty
                if not retrieved_output_paths and os.path.exists(host_output_temp_dir) and not os.listdir(host_output_temp_dir):
                    try:
                        os.rmdir(host_output_temp_dir)
                        print(f"Removed empty temporary output directory: {host_output_temp_dir}")
                    except OSError as e:
                        print(f"Could not remove empty directory {host_output_temp_dir}: {e}")

            except errors.NotFound:
                pass # Container might not have been created or already removed
            except Exception as e:
                print(f"Error during container cleanup of '{container_id}': {e}")
        
        # In case an exception occurred before the final return, ensure a result is always given.
        # This prevents the "local variable 'retrieved_output_paths' referenced before assignment" error.
        # This 'if' check is important because if the main try block completes, it will have returned already.
        if 'result' not in locals(): 
            return {
                "stdout": stdout,
                "stderr": stderr,
                "execution_time_seconds": execution_time,
                "retrieved_output_files": retrieved_output_paths,
                "status_code": status_code
            }


# --- Example Usage (for testing the tool) ---
if __name__ == "__main__":
    # 1. Create some dummy data and ensure directories exist
    if not os.path.exists(HOST_DATA_DIR): os.makedirs(HOST_DATA_DIR)
    if not os.path.exists(HOST_OUTPUT_DIR): os.makedirs(HOST_OUTPUT_DIR)

    # with open(os.path.join(HOST_DATA_DIR, "sales.csv"), "w") as f:
    #     f.write("Product,Sales\n")
    #     f.write("A,100\n")
    #     f.write("B,150\n")
    #     f.write("C,200\n")

    print("\n--- Test Case 1: Simple code execution with input/output files ---")
    code_to_run_1 = """
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os

df = pd.read_csv('sales.csv')
total_sales_per_product = df.groupby('Product')['Sales'].sum().reset_index()

print("Total Sales per Product:")
print(total_sales_per_product)

# Create a simple plot
sns.barplot(x='Product', y='Sales', data=df)
plt.savefig('sales_plot_sns.png')
print("Plot saved as sales_plot_sns.png")

# Create a cleaned/processed CSV
total_sales_per_product.to_csv('total_sales.csv', index=False)
print("Processed data saved as total_sales.csv")
"""
    result_1 = execute_sandboxed_code(
        code_to_run_1,
        input_files=["sales.csv"],
        output_files_expected=["sales_plot_sns.png", "total_sales.csv"]
    )
    print("\n--- Result 1 ---")
    print(result_1)
    if result_1:
        if result_1['retrieved_output_files']:
            print(f"Generated files for Test 1 in: {os.path.dirname(result_1['retrieved_output_files'][0])}")

    